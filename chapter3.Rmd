# Chapter 3: Logistic regression

## Data


```{r}
setwd("~/Tilastotiede/IODS-project")
alc <- read.csv(file = "data/alc.csv", row.names = 1)
dim(alc)
colnames(alc)

```
This data is from Portuguese secondary school and it describes the alcohol consumption habits. It was collected by using questionnaires and school reports. Here we have combined data set and they represent performing in Mathematics and Portuguese language.

More information can be found from [here](https://archive.ics.uci.edu/ml/datasets/Student+Performance).

## Hypothesis

If I have to guess Ill take these four variables that could explain high alcohol consumption.
Below there is some thoughts why.
*goout - going out with friends (numeric: from 1 - very low to 5 - very high)
  - Typically if one is going out often alcohol may play some role.
*studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours) 
  - If one is studing more often the alcohol consumption is lover.
*G3 - final grade (numeric: from 0 to 20, output target)
  - Final grade is often good if one havent drink so much
*absences - number of school absences (numeric: from 0 to 93)
  - Typically people that are not often seen at school are more often seen at bar.

<a href="#top">Back to top</a>

## Distribution and relationships

Here one can find correlation plot. I wanted to look hypothesized variables and some extras to see is there any better variables but not too many to keep plot easy to understand.
```{r}
library(GGally)
ggcorr(alc[colnames(alc) %in% c("goout", "absences", "G3", "freetime", "studytime", "failures", "alc_use")],
       palette = "RdBu", label = TRUE, label_round=2)

```
Free time shows good correlation but I will keep the hypothesized variables as they all show good correlation.

As we are going to use binary variable high_use here are some box plot.
```{r}
library(cowplot)
g1 <- ggplot(alc, aes(x = high_use, y = goout, col = sex)) +
  geom_boxplot()
g2 <- ggplot(alc, aes(x = high_use, y = studytime, col = sex)) +
  geom_boxplot()
g3 <- ggplot(alc, aes(x = high_use, y = G3, col = sex)) +
  geom_boxplot()
g4 <- ggplot(alc, aes(x = high_use, y = absences, col = sex)) +
  geom_boxplot()

plot_grid(g1,g2,g3,g4)
```
And here we can already somehow confirm some of the hypothesis as more out going increase the high alcohol use. If grades are lower especially for male the alcohol use is often higher and lastly some difference can be seen in absences. Contradictory, study time is not as good predictor as I thought it could be.

<a href="#top">Back to top</a>

## Logistic regression
```{r }
mod <- glm(high_use ~ goout + studytime + G3 + absences , data = alc)
summary(mod)
```
```{r }
coef(mod)
```
```{r }
Odds <-coef(mod) %>% exp
Confidence <- confint(mod) %>% exp
```
```{r }
cbind(Odds, Confidence)
```
Odds ratios tell basically how good predictors are the explanatory variables. If the value is higher than 1 variable predicts high use and if its smaller it predicts low use. In this case G3 is close to 1 and its confidence intervals are below and above 1 meaning that it is not good predictor. All the other predictor odds ratios and confidences are above (goout and absence) or below (studytime) 1. This gives the same interpretation as p-values from the statistical model.

<a href="#top">Back to top</a>

## Prediction power
```{r }
library(dplyr)
mod <- glm(high_use ~ goout + studytime  + absences , data = alc)

#prediction and observing the data
prob <- predict(mod, type = "response")
alc <- mutate(alc, probability = prob)
alc <- mutate(alc, prediction = probability > 0.5)
select(alc, failures, absences, studytime, high_use, probability, prediction) %>% tail(10)

table(high_use = alc$high_use, prediction = alc$prediction)

```
```{r}
g <- ggplot(alc, aes(x = probability, y = high_use, col = prediction))

# define the geom as points and draw the plot
g + geom_point()

# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction) %>% prop.table %>% addmargins

```


According to these tests my three predictive variables are not enough to reliably predict high alcohol use. Fortunately, most of the predictions are right.
The number table shows exactly the same thing as the proportion table. The model is predicting too much high alcohol users. From the tables one can read that 88/370. i.e. about 24% of the predicted variables are wrong.

Results are expected, as typically this complex data set is hard to predict. Against expectations the G3 variable (grades) was not good predictor and thus dropped out.

<a href="#top">Back to top</a>

## Cross-validation
```{r}
library(boot)
toCV <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

toCV(class = alc$high_use, prob = alc$probability)

cv <- cv.glm(data = alc, cost = toCV, glmfit = mod, K = 10)

# average number of wrong predictions in the cross validation
cv$delta[1]
```
The number of wrong predictions is near 0.24, so very similar to simplified model evaluation.